{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ce62a8-251f-4f9e-b375-e93a5861c3fe",
   "metadata": {},
   "source": [
    "# RAG ê¸°ì´ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c7374",
   "metadata": {},
   "source": [
    "## Enviornment (.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67655",
   "metadata": {},
   "source": [
    "## Tool ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9df40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e60bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "tools = [Add, Multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a45abc",
   "metadata": {},
   "source": [
    "## Tool Calling / Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf277aa0",
   "metadata": {},
   "source": [
    "\n",
    "### 1) OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a446bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm_with_tools = llm.bind_tools(tools=[add, multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a68204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_FhCkTbiHarD5Gy4hoSCPiAHp', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_PsBJHWXkQZuarX7s2mqKMRRR', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 88, 'total_tokens': 137}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-387c9513-f8fb-41a2-9205-1fc2d23930c1-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_FhCkTbiHarD5Gy4hoSCPiAHp'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_PsBJHWXkQZuarX7s2mqKMRRR'}] usage_metadata={'input_tokens': 88, 'output_tokens': 49, 'total_tokens': 137}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b789eaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_FhCkTbiHarD5Gy4hoSCPiAHp'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_PsBJHWXkQZuarX7s2mqKMRRR'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d35e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_0XV4yzJNQzJTLbEmkYEGpKhY', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_S3peK9N6vr2ZOMbiZV0wNDGn', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'Add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 105, 'total_tokens': 155}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c282b7d7-0773-4a9d-8d7a-b09c5ebdd652-0' tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_0XV4yzJNQzJTLbEmkYEGpKhY'}, {'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_S3peK9N6vr2ZOMbiZV0wNDGn'}] usage_metadata={'input_tokens': 105, 'output_tokens': 50, 'total_tokens': 155}\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=[Add, Multiply])\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdb543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_0XV4yzJNQzJTLbEmkYEGpKhY'},\n",
       " {'name': 'Add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_S3peK9N6vr2ZOMbiZV0wNDGn'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568b8480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DLIr9feoUMXu2AxOslUapcp3', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_Gy8hzf9D7AnTZSrtu4HblMlo', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'Add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 105, 'total_tokens': 155}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-66d20e52-3444-4a1d-93db-baa8aecac7ae-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_DLIr9feoUMXu2AxOslUapcp3'}, {'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_Gy8hzf9D7AnTZSrtu4HblMlo'}], usage_metadata={'input_tokens': 105, 'output_tokens': 50, 'total_tokens': 155}),\n",
       " ToolMessage(content='36', tool_call_id='call_DLIr9feoUMXu2AxOslUapcp3'),\n",
       " ToolMessage(content='60', tool_call_id='call_Gy8hzf9D7AnTZSrtu4HblMlo')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff4dd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 3 * 12 is 36, and the result of 11 + 49 is 60.', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 171, 'total_tokens': 197}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f36169bf-5415-45b8-be75-28e6871145d2-0', usage_metadata={'input_tokens': 171, 'output_tokens': 26, 'total_tokens': 197})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39c627",
   "metadata": {},
   "source": [
    "### 2) Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a121e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' id='run-db56dbad-e61c-4be7-938a-a608e03363b5-0' tool_calls=[{'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_7b241f31111e4449bbe7d90b33b9f393'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\")\n",
    "llm_with_tools = llm.bind_tools(tools=[Add, Multiply])\n",
    "\n",
    "# query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "query = \"what is 11 + 49? Also, What is 3 * 12?\"\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "329ae3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_7b241f31111e4449bbe7d90b33b9f393'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afbd3c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', id='run-b6ec5e12-1d95-460c-92b9-1dbaa5806a1d-0', tool_calls=[{'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_2d635c04e9d34b7e9ae7ca63ddf387a2'}]),\n",
       " FunctionMessage(content='60', name='Add')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, FunctionMessage\n",
    "\n",
    "# messages = [HumanMessage(query)]\n",
    "messages = []\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(FunctionMessage(tool_output, name=tool_call[\"name\"]))\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1686a739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It looks like you're trying to ask me a math question!\\n\\nThe function `f(x) = 60` is a constant function, which means that it always returns the same value, regardless of the input `x`.\\n\\nIn other words, for any value of `x`, the output of this function will be exactly `60`.\\n\\nIs there anything else you'd like to know or discuss?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "Ollama(model=\"llama3\").invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7142521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is 11 + 49? Also, What is 3 * 12?'),\n",
       " AIMessage(content='', id='run-7a75de94-4eed-4a67-9e18-5d62295519fc-0', tool_calls=[{'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_cf2f9077ed624807affc3b9a96ee148d'}]),\n",
       " FunctionMessage(content='60', name='Add')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91765afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the operation results:\\n\\n* 11 + 49 = 60 (based on the \"Add\" function call)\\n* 3 * 12 = ? (no information provided about this multiplication)\\n\\nSo, we can confidently answer the first question:\\n\\nWhat is 11 + 49? => 60\\n\\nHowever, we cannot provide an answer for the second question without additional information!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"\"\"Breifely answer the question based on the following operation results:\n",
    "                                               {context}\n",
    "                                               \n",
    "                                               Question:{question}\n",
    "                                               Answer:\"\"\")\n",
    "chat_model = ChatOllama(model=\"llama3\")\n",
    "llm_chain = chat_prompt | chat_model| StrOutputParser()\n",
    "llm_chain.invoke({\"context\":messages, \"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c5e306e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23 ë”í•˜ê¸° 17ì€ 40ì…ë‹ˆë‹¤. ğŸ˜Š'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_query(query):\n",
    "    messages = []\n",
    "    ai_msg = llm_with_tools.invoke(query)\n",
    "    messages.append(ai_msg)\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "        tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "        messages.append(FunctionMessage(tool_output, name=tool_call[\"name\"]))   \n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_template(\"\"\"ë‹¤ìŒ ê³„ì‚°ì— ê·¼ê±°í•˜ì—¬ ì§ˆë¬¸ì— ê°„ë‹¨íˆ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”:\n",
    "                                                {context}\n",
    "                                                \n",
    "                                                Question:{question}\n",
    "                                                Answer:\"\"\")\n",
    "    chat_model = ChatOllama(model=\"llama3\")\n",
    "    llm_chain = chat_prompt | chat_model| StrOutputParser()\n",
    "    response = llm_chain.invoke({\"context\":messages, \"question\":query})\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return \"No response found.\"\n",
    "\n",
    "query = \"23 ë”í•˜ê¸° 17ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?\"\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3208ca",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20ed79",
   "metadata": {},
   "source": [
    "#### 1) (pydantic) Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64101cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Car(BaseModel):\n",
    "    \"\"\"Information about a car.\"\"\"\n",
    "    make: Optional[str] = Field(default=None, description=\"The make of the car\")\n",
    "    model_name: Optional[str] = Field(default=None, description=\"The model name of the car\")\n",
    "    model_year: Optional[int] = Field(\n",
    "        default=None, description=\"The year the car model was manufactured\"\n",
    "    )\n",
    "    color: Optional[str] = Field(default=None, description=\"The color of the car\")\n",
    "    price: Optional[float] = Field(default=None, description=\"The price of the car\")\n",
    "    mileage: Optional[float] = Field(default=None, description=\"The mileage of the car\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594015b6",
   "metadata": {},
   "source": [
    "#### 2) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e7f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a2fbe",
   "metadata": {},
   "source": [
    "#### 3) OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087b7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a99eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make='BYD' model_name='ëŒí•€' model_year=None color=None price=19000000.0 mileage=None\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "í˜„ì¬ í™˜ê²½ë¶€ì™€ ì‚°ì—…í†µìƒìì›ë¶€ê°€ ì‹¬ì‚¬ ì¤‘ì¸ BYDì˜ ì†Œí˜• í•´ì¹˜ë°± ì°¨ëŸ‰ì¸ â€˜ëŒí•€â€™ê³¼ ì¤‘í˜• ì„¸ë‹¨ ì°¨ëŸ‰ì¸ â€˜ì”°â€™ì˜ ì¤‘êµ­ ë‚´ ìµœì € íŒë§¤ ê°€ê²©ì€ ê°ê° 1900ë§Œ ì›, 3900ë§Œ ì›ì´ë‹¤. íŠ¹íˆ ëŒí•€ì€ êµ­ë‚´ì—ì„œ ê°€ì¥ ê°’ì‹¼ ê²½í˜• ì „ê¸°ì°¨ì¸ â€˜ê¸°ì•„ ë ˆì´EV(ì„¸ì œ í˜œíƒ ì „ 2775ë§Œ ì›)â€™ì™€ ë¹„êµí•´ë„ ì••ë„ì ìœ¼ë¡œ ì €ë ´í•˜ë‹¤.\n",
    "ì”°ì€ BYDì˜ ì…€íˆ¬ë³´ë””(CTB) ê¸°ìˆ ì´ ì„¸ê³„ ìµœì´ˆë¡œ ì ìš©ëœ ì°¨ëŸ‰ìœ¼ë¡œ ê°€ê²© ëŒ€ë¹„ ë†’ì€ ì„±ëŠ¥ì„ ìë‘í•œë‹¤. CTBë€ ì°¨ëŸ‰ ë³¸ì²´ì™€ ë°°í„°ë¦¬Â·ë°°í„°ë¦¬ê´€ë¦¬ì‹œìŠ¤í…œ(BMS) ë“±ì„ í•˜ë‚˜ë¡œ í†µí•©í•´ ê°•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ëª¨ë‘ ë†’ì´ëŠ” ê¸°ìˆ ì„ ëœ»í•œë‹¤. ë‘ ì°¨ëŸ‰ ëª¨ë‘ ìœ ëŸ½ì˜ ì‹ ì°¨ ì•ˆì •ì„± í”„ë¡œê·¸ë¨(euro NCAP)ì—ì„œ ìµœê³  ë“±ê¸‰ì„ ë°›ê¸°ë„ í–ˆë‹¤.\n",
    "í•œêµ­ ì‹œì¥ ì§„ì…ì„ ìœ„í•´ BYDê°€ í˜„ì§€ íŒë§¤ê°€ì™€ ìœ ì‚¬í•œ ìˆ˜ì¤€ìœ¼ë¡œ ê°€ê²©ì„ ì±…ì •í•  ê°€ëŠ¥ì„±ë„ ìˆë‹¤. í†µìƒ êµ­ë‚´ ì‹œì¥ ì§„ì… ì‹œ ê°€ê²©ì„ ë” ë†’ì—¬ì¡ëŠ” ê²Œ ì¼ë°˜ì ì´ì§€ë§Œ ì¤‘êµ­ì‚° ì œí’ˆì— ëŒ€í•œ í•œêµ­ì˜ ë¶€ì •ì  ì¸ì‹ì„ ê³ ë ¤í•´ ê°€ê²© ê²½ìŸë ¥ì„ ìµœìš°ì„ ì ìœ¼ë¡œ í™•ë³´í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ìŠ¤ìœ„ìŠ¤ íˆ¬ìì€í–‰(IB) UBSì— ë”°ë¥´ë©´ BYDëŠ” ë°°í„°ë¦¬, ì°¨ëŸ‰ìš© ë°˜ë„ì²´, ì†Œí”„íŠ¸ì›¨ì–´ ë“± ì „ì²´ ë¶€í’ˆ 75%ì— ëŒ€í•œ ìˆ˜ì§ ê³„ì—´í™”ë¥¼ ì´ë£¨ë©´ì„œ ê²½ìŸì‚¬ ëŒ€ë¹„ 30% ìˆ˜ì¤€ì˜ ê°€ê²© ìš°ìœ„ë¥¼ í™•ë³´í•˜ê³  ìˆë‹¤. ì•„ìš¸ëŸ¬ ë¦¬íŠ¬Â·ì¸ì‚°Â·ì² (LFP) ë°°í„°ë¦¬ì— ëŒ€í•œ í™˜ê²½ë¶€ì˜ ë¶ˆë¦¬í•œ ê·œì •ì—ë„ ì¼ì • ìˆ˜ì¤€ì˜ ë³´ì¡°ê¸ˆ í™•ë³´ë„ ê°€ëŠ¥í•˜ë‹¤. í˜„ì¬ ëŒí•€ê³¼ ì”°ì˜ íŒë§¤ ê°€ê²©ì€ êµ­ë‚´ ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ ì „ì•¡ ì§€ì› ê¸°ì¤€ì¸ 5500ë§Œ ì›ì„ ì¶©ì¡±í•œë‹¤. ìœ ëŸ½ ì¸ì¦ ê¸°ì¤€ì„ ë§Œì¡±ì‹œí‚¤ëŠ” ìµœëŒ€ 427ã(ëŒí•€), 570ã(ì”°)ì— ì´ë¥´ëŠ” 1íšŒ ì¶©ì „ ì£¼í–‰ê±°ë¦¬ë„ ìœ ë¦¬í•œ ìš”ì†Œë‹¤.\n",
    "BYDì˜ ëŒ€í•­ë§ˆë¡œëŠ” ìµœê·¼ ê¸°ì•„ê°€ ì¶œì‹œí•œ ì†Œí˜• ìŠ¤í¬ì¸ ìœ í‹¸ë¦¬í‹°ì°¨ëŸ‰(SUV) â€˜EV3â€™ê°€ ê¼½íŒë‹¤. EV3ëŠ” ë‹ˆì¼ˆÂ·ì½”ë°œíŠ¸Â·ë§ê°„(NCM) ë°°í„°ë¦¬ë¥¼ íƒ‘ì¬í•´ ë¡±ë ˆì¸ì§€ ëª¨ë¸ ê¸°ì¤€ 1íšŒ ì¶©ì „ì— 501ã ì£¼í–‰ê±°ë¦¬ë¥¼ í™•ë³´í–ˆë‹¤. ê°€ê²©ì€ ë³´ì¡°ê¸ˆ ì ìš© ì‹œ 3000ë§Œ ì› ì¤‘ë°˜ëŒ€ë¡œ ì „ê¸°ì°¨ ëŒ€ì¤‘í™”ë¼ëŠ” ëª©í‘œë¥¼ ì´ë£¨ê¸° ìœ„í•œ ê¸°ì•„ì˜ ì£¼ë ¥ ëª¨ë¸ì´ë‹¤. KGëª¨ë¹Œë¦¬í‹°ì˜ ì½”ë€ë„EV(3000ë§Œ ì›ëŒ€)ë„ BYDì˜ ê²½ìŸ ìƒëŒ€ë‹¤.\n",
    "\"\"\"\n",
    "response = runnable.invoke({\"text\": text})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef1ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about cars.\"\"\"\n",
    "    cars: List[Car] = Field(\n",
    "        default=None, description=\"Extracted information about cars\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c8e43",
   "metadata": {},
   "source": [
    "#### 4) ì—¬ëŸ¬ ê°œì˜ Entity ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e83c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars=[Car(make='BYD', model_name='ëŒí•€', model_year=None, color=None, price=19000000.0, mileage=None), Car(make='BYD', model_name='ì”°', model_year=None, color=None, price=39000000.0, mileage=None), Car(make='ê¸°ì•„', model_name='ë ˆì´EV', model_year=None, color=None, price=27750000.0, mileage=None), Car(make='ê¸°ì•„', model_name='EV3', model_year=None, color=None, price=30000000.0, mileage=None), Car(make='KGëª¨ë¹Œë¦¬í‹°', model_name='ì½”ë€ë„EV', model_year=None, color=None, price=30000000.0, mileage=None)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about cars.\"\"\"\n",
    "    cars: List[Car] = Field(\n",
    "        default=None, description=\"Extracted information about cars\"\n",
    "    )\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Data)\n",
    "response = runnable.invoke({\"text\": text})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e928d",
   "metadata": {},
   "source": [
    "### 5) Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc53e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make=None model_name='ì½”ë€ë„EV' model_year=None color=None price=3000.0 mileage=None\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm. Only extract relevant information from the text.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "TEXT: {context}\n",
    "QUESTION: {question}\n",
    "JSON:\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\", temperature=0)\n",
    "chain = prompt | llm.with_structured_output(schema=Car)\n",
    "response = chainÂ .invoke({\"context\": text, \"question\": \"Describe ì½”ë€ë„\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43244c7",
   "metadata": {},
   "source": [
    "## API í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad9db475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Stock(BaseModel):\n",
    "    \"\"\"Trading Stock\"\"\"\n",
    "\n",
    "    ticker: Optional[str] = Field(default=None, description=\"\"\"The ticker of the stock (\"005930\", \"AAPL\", ...)\"\"\")\n",
    "    start_date: Optional[str] = Field(default=None, description=\"\"\"The start trading date (\"2021-01-01\", ...)\"\"\")\n",
    "    end_date: Optional[str] = Field(default=None, description=\"\"\"The end trading date (\"2021-12-31\", ...)\"\"\")\n",
    "\n",
    "class Market(BaseModel):\n",
    "    \"\"\"Stock market index\"\"\"\n",
    "\n",
    "    ticker: Optional[str] = Field(default=None, description=\"\"\"The ticker of the market index based on the following list(KS11, VIX, ...):\n",
    "        - KS11: KOSPI ì§€ìˆ˜, ì½”ìŠ¤í”¼ ì§€ìˆ˜\n",
    "        - KQ11: KOSDAQ ì§€ìˆ˜, ì½”ìŠ¤ë‹¥ ì§€ìˆ˜\n",
    "        - KS200: KOSPI 200, ì½”ìŠ¤í”¼ 200\n",
    "        - DJI: ë‹¤ìš°ì¡´ìŠ¤ ì§€ìˆ˜, Dow Jones Industrial Average\n",
    "        - IXIC: ë‚˜ìŠ¤ë‹¥ ì¢…í•©ì§€ìˆ˜, NASDAQ Composite\n",
    "        - S&P500: S&P500 ì§€ìˆ˜, NYSE\n",
    "        - RUT: ëŸ¬ì…€2000 ì§€ìˆ˜, Russell 2000\n",
    "        - VIX: VIX ì§€ìˆ˜, CBOE Volatility Index\n",
    "        - SSEC: ìƒí•´ ì¢…í•©ì§€ìˆ˜, Shanghai Composite\n",
    "        - HSI: í•­ì…ì§€ìˆ˜, Hang Seng\n",
    "        - N225: ì¼ë³¸ ë‹›ì¼€ì´ì§€ìˆ˜, Nikkei 225\n",
    "        - FTSE: ì˜êµ­ FTSE100, FTSE 100\n",
    "        - FCHI: í”„ë‘ìŠ¤ CAC40 ì§€ìˆ˜, CAC 40\n",
    "        - GDAXI: ë…ì¼ ë‹¥ìŠ¤ì§€ìˆ˜, DAX 30\"\"\")\n",
    "    start_date: Optional[str] = Field(default=None, description=\"\"\"The start trading date (\"2021-01-01\", ...)\"\"\")\n",
    "    end_date: Optional[str] = Field(default=None, description=\"\"\"The end trading date (\"2021-12-31\", ...)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6b3c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Stock', 'args': {'ticker': '005930', 'start_date': '2023-01-01', 'end_date': '2023-12-31'}, 'id': 'call_f86d6f49eac64fe583ad5a9d17343367'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\")\n",
    "llm_with_tools = llm.bind_tools(tools=[Stock, Market])\n",
    "\n",
    "query = \"ì‚¼ì„±ì „ìì˜ 2023ë…„ ì£¼ê°€\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ef6720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Stock', 'args': {'ticker': 'TSLA', 'start_date': '2024-03-01', 'end_date': '2024-03-31'}, 'id': 'call_3014e3c100594fde9b71e1d00b80b0f5'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"2024ë…„ 3ì›” í…ŒìŠ¬ë¼\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003fad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Market', 'args': {'ticker': 'IXIC', 'start_date': '2022-01-01', 'end_date': '2022-12-31'}, 'id': 'call_5e82cdcdaa2f413b9decf5233df0cf9e'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"2022ë…„ ë‚˜ìŠ¤ë‹¥ ì§€ìˆ˜\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c47563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Market', 'args': {'ticker': 'KQ11', 'start_date': '2019-07-01', 'end_date': '2019-07-31'}, 'id': 'call_0d1ba771788d4ec6be5c938e7b1eae9e'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"ì½”ìŠ¤ë‹¥ ì§€ìˆ˜ 2019ë…„ 7ì›”\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32e752e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>UpDown</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Amount</th>\n",
       "      <th>MarCap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>696.38</td>\n",
       "      <td>697.97</td>\n",
       "      <td>692.76</td>\n",
       "      <td>696.00</td>\n",
       "      <td>734433278</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>1</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5156354340512</td>\n",
       "      <td>238458830094666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>695.80</td>\n",
       "      <td>699.44</td>\n",
       "      <td>693.19</td>\n",
       "      <td>696.25</td>\n",
       "      <td>696445726</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4052249681800</td>\n",
       "      <td>238565438926786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>697.68</td>\n",
       "      <td>698.89</td>\n",
       "      <td>689.86</td>\n",
       "      <td>693.04</td>\n",
       "      <td>676298786</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.21</td>\n",
       "      <td>3979382946906</td>\n",
       "      <td>237389805604275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-04</th>\n",
       "      <td>693.96</td>\n",
       "      <td>694.63</td>\n",
       "      <td>682.73</td>\n",
       "      <td>691.27</td>\n",
       "      <td>763516530</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>4132922883851</td>\n",
       "      <td>236950136647970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>692.86</td>\n",
       "      <td>694.39</td>\n",
       "      <td>686.93</td>\n",
       "      <td>694.17</td>\n",
       "      <td>729813499</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>4048011198486</td>\n",
       "      <td>237965631550822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close     Volume  Change  UpDown  Comp  \\\n",
       "Date                                                                          \n",
       "2019-07-01  696.38  697.97  692.76  696.00  734433278  0.0079       1  5.47   \n",
       "2019-07-02  695.80  699.44  693.19  696.25  696445726  0.0004       1  0.25   \n",
       "2019-07-03  697.68  698.89  689.86  693.04  676298786 -0.0046       2 -3.21   \n",
       "2019-07-04  693.96  694.63  682.73  691.27  763516530 -0.0026       2 -1.77   \n",
       "2019-07-05  692.86  694.39  686.93  694.17  729813499  0.0042       1  2.90   \n",
       "\n",
       "                   Amount           MarCap  \n",
       "Date                                        \n",
       "2019-07-01  5156354340512  238458830094666  \n",
       "2019-07-02  4052249681800  238565438926786  \n",
       "2019-07-03  3979382946906  237389805604275  \n",
       "2019-07-04  4132922883851  236950136647970  \n",
       "2019-07-05  4048011198486  237965631550822  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FinanceDataReader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "df = fdr.DataReader(\"KQ11\", \"2019-07-01\", \"2019-07-31\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "920b7b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005930 2022-03-01 2022-03-15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-02</th>\n",
       "      <td>72300</td>\n",
       "      <td>72400</td>\n",
       "      <td>71500</td>\n",
       "      <td>71700</td>\n",
       "      <td>12481430</td>\n",
       "      <td>-0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03</th>\n",
       "      <td>72300</td>\n",
       "      <td>73100</td>\n",
       "      <td>72200</td>\n",
       "      <td>72900</td>\n",
       "      <td>13232638</td>\n",
       "      <td>0.016736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>72700</td>\n",
       "      <td>72700</td>\n",
       "      <td>71200</td>\n",
       "      <td>71500</td>\n",
       "      <td>13409634</td>\n",
       "      <td>-0.019204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>70000</td>\n",
       "      <td>70600</td>\n",
       "      <td>69900</td>\n",
       "      <td>70100</td>\n",
       "      <td>18617138</td>\n",
       "      <td>-0.019580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>68800</td>\n",
       "      <td>70000</td>\n",
       "      <td>68700</td>\n",
       "      <td>69500</td>\n",
       "      <td>15828269</td>\n",
       "      <td>-0.008559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close    Volume    Change\n",
       "Date                                                      \n",
       "2022-03-02  72300  72400  71500  71700  12481430 -0.005548\n",
       "2022-03-03  72300  73100  72200  72900  13232638  0.016736\n",
       "2022-03-04  72700  72700  71200  71500  13409634 -0.019204\n",
       "2022-03-07  70000  70600  69900  70100  18617138 -0.019580\n",
       "2022-03-08  68800  70000  68700  69500  15828269 -0.008559"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"2022ë…„ 3ì›” 1ì¼ë¶€í„° 2022ë…„ 3ì›” 15ì¼ê¹Œì§€ ì‚¼ì„±ì „ì ì£¼ê°€\"\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "ticker = ai_msg.tool_calls[0]['args']['ticker']\n",
    "start_date = ai_msg.tool_calls[0]['args']['start_date']\n",
    "end_date = ai_msg.tool_calls[0]['args']['end_date']\n",
    "\n",
    "print(ticker, start_date, end_date)\n",
    "df = fdr.DataReader(ticker, start_date, end_date)\n",
    "df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127af7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
